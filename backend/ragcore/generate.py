# ragcore/generate.py
import os,json,requests
from openai import OpenAI

SYSTEM = """You are a precise assistant. 
- Use ONLY provided context to answer.
- If missing info, say whatâ€™s missing.
- Cite sources inline as [n] where n indexes the context list."""

BASE_URL = os.getenv("BASE_URL", "https://nala.ntu.edu.sg") 
API_KEY = os.getenv("API_KEY", "pk_LearnUS_176q45") 

def build_prompt(query: str, context_chunks: list[dict]):
    ctx = []
    for i, c in enumerate(context_chunks, 1):
        src = c["chunk"]["meta"].get("filename", "unknown")
        ctx.append(f"[{i}] ({src})\n{c['chunk']['text']}")
    ctx_txt = "\n\n".join(ctx)
    user = f"Question: {query}\n\nContext:\n{ctx_txt}\n\nAnswer with citations like [1], [2]."
    return SYSTEM, user

def call_llm(query: str, context_chunks: list[dict], model="gpt-4o-mini"):
    system, user = build_prompt(query, context_chunks)
    url = f"{BASE_URL}/api/llm"
    headers = {"X-API-Key": API_KEY, "Content-Type": "application/json"}
    payload = {"text": user, "system": system}
    r = requests.post(url, headers=headers, data=json.dumps(payload), timeout=30)
    r.raise_for_status()
    # Adjust this if your API returns a different field for the answer
    return r.json().get("answer", r.text)
